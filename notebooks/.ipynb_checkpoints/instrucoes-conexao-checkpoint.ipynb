{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b76078-c281-44f2-9aa9-b4d666eb9ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessão inicializada com o token de acesso da AWS\n",
      "Spark inicializado com sucesso com as credenciais da AWS\n",
      "CPU times: user 1.59 s, sys: 641 ms, total: 2.23 s\n",
      "Wall time: 9.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import boto3\n",
    "import findspark\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import col, round, concat_ws\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark.pandas as ps\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "os.environ['PYARROW_IGNORE_TIMEZONE'] = str(1)\n",
    "\n",
    "AWS_KEY=\"AKIA2BWSG3FNNNB5ICXW\"\n",
    "AWS_SECRET=\"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\"\n",
    "\n",
    "client = boto3.client(\n",
    "    service_name='sts',\n",
    "    region_name='us-east-1',\n",
    "    aws_access_key_id=AWS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET)\n",
    "\n",
    "credentials = client.get_session_token()\n",
    "\n",
    "print(\"Sessão inicializada com o token de acesso da AWS\")\n",
    "\n",
    "AccessKeyId = credentials['Credentials']['AccessKeyId']\n",
    "SecretAccessKey = credentials['Credentials']['SecretAccessKey']\n",
    "SessionToken = credentials['Credentials']['SessionToken']\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"queries\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\") \\\n",
    "    .config(\"spark.sql.legacy.parquet.int96RebaseModeInRead\", \"CORRECTED\") \\\n",
    "    .config(\"spark.sql.legacy.parquet.int96RebaseModeInWrite\", \"CORRECTED\") \\\n",
    "    .config(\"spark.sql.legacy.parquet.datetimeRebaseModeInRead\", \"CORRECTED\") \\\n",
    "    .config(\"spark.sql.legacy.parquet.datetimeRebaseModeInWrite\", \"CORRECTED\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", AccessKeyId) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", SecretAccessKey) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.session.token\", SessionToken) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.us-east-1.amazonaws.com\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark inicializado com sucesso com as credenciais da AWS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b723bf6-898c-448a-9656-5a2eaf52c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterioDeRateio_id=10\n",
    "ano=2022\n",
    "\n",
    "df = spark.read.parquet(f's3a://datalake-planisa-dev/kpih/custos-unitarios-assistenciais/sadts/criterioDeRateio_id={10}/ano={2022}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281bb25b-5bee-4a5b-b216-6206a0a51b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
